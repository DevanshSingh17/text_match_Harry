{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b178c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\OneDrive\\Documents\\python programs\\chapter_matcher\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de69318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine lines into multi-line chunks\n",
    "def chunk_lines(lines, window_size=5):\n",
    "    chunks = []\n",
    "    indices = []\n",
    "    for i in range(len(lines) - window_size + 1):\n",
    "        chunk = lines[i:i + window_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        indices.append((i, i + window_size))  # start, end index\n",
    "    return chunks, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce74d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text files and prepare chunks\n",
    "def read_text_files_from_directory(directory_path, chunk_size=5):\n",
    "    chapters = []\n",
    "    original_lines = {}  # for retrieving original text\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            chapter_name = os.path.splitext(filename)[0]\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(filepath, 'r', encoding='latin-1') as f:\n",
    "                    lines = f.readlines()\n",
    "\n",
    "            clean_lines = [line.strip() for line in lines if line.strip()]\n",
    "            original_lines[chapter_name] = clean_lines\n",
    "            line_chunks, chunk_indices = chunk_lines(clean_lines, window_size=chunk_size)\n",
    "            chapters.append((chapter_name, line_chunks, chunk_indices))\n",
    "\n",
    "    return chapters, original_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6910e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all chapter chunks\n",
    "def encode_chapters(model, chapters):\n",
    "    encoded_chapters = []\n",
    "    for chapter_name, chunks, indices in chapters:\n",
    "        embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "        encoded_chapters.append((chapter_name, chunks, indices, embeddings))\n",
    "    return encoded_chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b857329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best match and highlight best line\n",
    "def find_best_match(query, encoded_chapters, original_lines, model):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    best_score = 0\n",
    "    best_chunk = \"\"\n",
    "    best_line = \"\"\n",
    "    best_chapter = \"\"\n",
    "    best_lines_range = (0, 0)\n",
    "\n",
    "    for chapter_name, chunks, indices, embeddings in encoded_chapters:\n",
    "        cosine_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "        best_score_idx = torch.argmax(cosine_scores).item()\n",
    "        score = cosine_scores[best_score_idx].item()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_chunk = chunks[best_score_idx]\n",
    "            best_lines_range = indices[best_score_idx]\n",
    "            best_chapter = chapter_name\n",
    "\n",
    "    # Now, find best matching individual line within the best chunk\n",
    "    start, end = best_lines_range\n",
    "    lines_in_chunk = original_lines[best_chapter][start:end]\n",
    "    line_embeddings = model.encode(lines_in_chunk, convert_to_tensor=True)\n",
    "    line_scores = util.pytorch_cos_sim(query_embedding, line_embeddings)[0]\n",
    "    best_line_idx = torch.argmax(line_scores).item()\n",
    "    best_line = lines_in_chunk[best_line_idx]\n",
    "\n",
    "    return lines_in_chunk, best_line, best_chapter, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6206774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory_path = \"chapters\"\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "chapters, original_lines = read_text_files_from_directory(directory_path, chunk_size=3)\n",
    "encoded_chapters = encode_chapters(model, chapters)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b6fdde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📖 Best match from: J. K. Rowling - Harry Potter 1 - Sorcerer's Stone\n",
      "🧩 Context:\n",
      ">>> his head. As he measured, he said, \"Every Ollivander wand has a core of  <<<\n",
      "a powerful magical substance, Mr. Potter. We use unicorn hairs, phoenix\n",
      "tail feathers, and the heartstrings of dragons. No two Ollivander wands\n",
      "\n",
      "🔍 Similarity: 63.47%\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter your query: \")\n",
    "    lines_in_chunk, best_line, best_chapter, score = find_best_match(query, encoded_chapters, original_lines, model)\n",
    "\n",
    "    print(f\"\\n📖 Best match from: {best_chapter}\")\n",
    "    print(\"🧩 Context:\")\n",
    "    for line in lines_in_chunk:\n",
    "        if line == best_line:\n",
    "            print(f\">>> {line}  <<<\")  # Highlight the best line\n",
    "        else:\n",
    "            print(line)\n",
    "    print(f\"\\n🔍 Similarity: {score * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
